# Data Model: Vision-Language-Action (VLA) Integration

## Entities

### Voice Command
**Description**: Natural language instruction provided via voice input, converted to text for processing in the VLA pipeline
**Attributes**:
- id: Unique identifier for the voice command
- audio_data: Raw audio data or reference to audio file
- transcribed_text: Text representation of the voice command after Whisper processing
- timestamp: When the command was received
- confidence_score: Confidence level of the speech-to-text conversion
- language_code: Language of the original voice command

### Intent Graph
**Description**: Structured representation of the recognized intent that maps to robotic capabilities in the VLA system
**Attributes**:
- id: Unique identifier for the intent graph
- command_text: Original text command that generated this intent
- recognized_entities: Parsed objects, locations, and actions from the command
- robot_capabilities: Matching robotic capabilities that can fulfill the intent
- priority_level: Priority for execution in case of multiple simultaneous commands
- validation_status: Whether the intent is valid and achievable with available resources

### ROS 2 Action Graph
**Description**: Executable sequence of actions generated by LLM planning for humanoid robot execution in the VLA pipeline
**Attributes**:
- id: Unique identifier for the action graph
- root_task: Primary task that the action graph fulfills
- action_sequence: Ordered sequence of ROS 2 actions to execute
- dependencies: Relationships between actions (precedence, parallelism)
- estimated_duration: Predicted time to complete the entire action sequence
- resource_requirements: Robot resources needed for execution (manipulators, sensors, etc.)

### VLA Pipeline
**Description**: End-to-end system connecting voice recognition, language processing, and robotic action execution for humanoid robots
**Attributes**:
- id: Unique identifier for the pipeline instance
- status: Current state (idle, processing_voice, planning, executing, completed, failed)
- voice_command_ref: Reference to the original voice command
- intent_graph_ref: Reference to the processed intent graph
- action_graph_ref: Reference to the generated ROS 2 action graph
- execution_log: Timeline of execution events and results
- success_rate: Historical success rate for similar commands

## Relationships

### Voice Command → Intent Graph
- A voice command is processed to create one intent graph
- One-to-one relationship with cascade delete (intent graph deleted when voice command is removed)

### Intent Graph → ROS 2 Action Graph
- An intent graph is translated by the LLM into one ROS 2 action graph
- One-to-one relationship with cascade delete (action graph deleted when intent graph is removed)

### ROS 2 Action Graph → VLA Pipeline
- An action graph is executed as part of one VLA pipeline instance
- One-to-many relationship (one pipeline can execute multiple action graphs sequentially)

## Validation Rules

### From Requirements:
- **FR-001**: Voice commands must be converted to text with high accuracy (≥90% for clear speech)
- **FR-002**: Intent recognition must properly map to robotic actions
- **FR-004**: ROS 2 action graphs must be executable by humanoid robots
- **FR-005**: End-to-end VLA pipeline must execute successfully
- **FR-006**: Documentation must be in Markdown format
- **FR-007**: All content must include IEEE citations
- **FR-008**: All pages must include code examples and diagrams
- **FR-009**: All pages must contain ≤1,500 tokens for RAG compatibility
- **FR-010**: Examples must be reproducible via Spec-Kit and Claude Code
- **FR-011**: Content must focus exclusively on humanoid robots

### Additional Constraints:
- Voice command confidence scores must be >0.7 for processing
- Intent graphs must map to at least one available robot capability
- Action graphs must have valid ROS 2 action names and parameters
- VLA pipeline execution logs must record success/failure of each action
- All entities must have proper timestamps for audit trail